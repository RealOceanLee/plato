# maskcrypt_client.py
import torch
import copy
from torch.utils.data import DataLoader, Subset


class MaskCryptClient:
    def __init__(self, client_id, config, dataset, is_byzantine=False, model_class=None):
        self.client_id = client_id
        self.config = config
        self.dataset = dataset
        self.is_byzantine = is_byzantine
        self.model_class = model_class
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # æ”»å‡»ç±»å‹ä»é…ç½®è¯»å–ï¼Œé»˜è®¤ä¸º random_weights
        self.attack_type = config.get('byzantine_attack_type', 'random')

        # ç¼“å­˜æœ¬åœ°ç»“æœ
        self.local_weights = None
        self.weight_update = None
        self.global_weights = None

        # åˆå§‹åŒ–æ—¶æ‰“å°æ‹œå åº­èº«ä»½
        if self.is_byzantine:
            print(f"  ğŸ˜ˆ å®¢æˆ·ç«¯ {self.client_id} åˆå§‹åŒ–ä¸ºæ‹œå åº­èŠ‚ç‚¹ | æ”»å‡»ç±»å‹: {self.attack_type}")

    def get_data(self, max_samples=200):
        """ç”¨äºé¢„èšç±»é˜¶æ®µé‡‡æ ·å°‘é‡æ˜æ–‡æ•°æ®"""
        if len(self.dataset) == 0:
            raise ValueError(f"å®¢æˆ·ç«¯ {self.client_id} æ•°æ®é›†ä¸ºç©º")
        n_samples = min(max_samples, len(self.dataset))
        indices = torch.randperm(len(self.dataset))[:n_samples]
        subset = Subset(self.dataset, indices)
        loader = DataLoader(subset, batch_size=n_samples, shuffle=False)
        data, targets = next(iter(loader))
        return data.to(self.device), targets.to(self.device)

    def update_global_weights(self, global_weights):
        # âœ… ä¼˜åŒ–ï¼šç›´æ¥å­˜å‚¨æƒé‡ï¼Œä¸æ”¹å˜è®¾å¤‡
        self.global_weights = copy.deepcopy(global_weights)

    def local_train(self, global_weights, epochs=1, current_round=1):
        # âœ… ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æƒé‡ï¼Œé¿å…è®¾å¤‡è½¬æ¢
        if not hasattr(self, 'model') or self.model is None:
            self.model = self.model_class().to(self.device)

        # ç›´æ¥åŠ è½½æƒé‡åˆ°è®¾å¤‡
        self.model.load_state_dict(global_weights)

        self.model.train()

        # âœ… å®‰å…¨è·å–å­¦ä¹ ç‡
        lr = self.config.get('learning_rate', 0.01)
        optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)
        criterion = torch.nn.CrossEntropyLoss()

        # âœ… ä¼˜åŒ–ï¼šç®€åŒ–æ•°æ®åŠ è½½å™¨é…ç½®
        train_loader = DataLoader(
            self.dataset,
            batch_size=self.config.get('batch_size', 32),
            shuffle=True,
            num_workers=0,
            pin_memory=False
        )

        for _ in range(epochs):
            for data, target in train_loader:
                data, target = data.to(self.device), target.to(self.device)
                optimizer.zero_grad()
                output = self.model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()

        # âœ… è·å–æœ¬åœ°æƒé‡
        local_weights = {k: v for k, v in self.model.state_dict().items()}
        weight_update = {k: local_weights[k] - global_weights[k] for k in global_weights}

        # âœ… æ‹œå åº­æ”»å‡»æ³¨å…¥
        if self.is_byzantine:
            if self.attack_type == "random" or self.attack_type == "random_weights":
                # éšæœºæƒé‡æ”»å‡»
                for k in local_weights:
                    local_weights[k] = torch.randn_like(local_weights[k])
                weight_update = {k: local_weights[k] - global_weights[k] for k in global_weights}
                print(f"  ğŸ˜ˆ [Round {current_round}] å®¢æˆ·ç«¯ {self.client_id} å‘èµ·æ”»å‡»: random_weights")

            elif self.attack_type == "sign_flip":
                # ç¬¦å·ç¿»è½¬æ”»å‡»
                weight_update = {k: -v for k, v in weight_update.items()}
                local_weights = {k: global_weights[k] + weight_update[k] for k in global_weights}
                print(f"  ğŸ˜ˆ [Round {current_round}] å®¢æˆ·ç«¯ {self.client_id} å‘èµ·æ”»å‡»: sign_flip")

            elif self.attack_type == "zero_update":
                # é›¶æ›´æ–°æ”»å‡»
                weight_update = {k: torch.zeros_like(v) for k, v in weight_update.items()}
                local_weights = copy.deepcopy(global_weights)
                print(f"  ğŸ˜ˆ [Round {current_round}] å®¢æˆ·ç«¯ {self.client_id} å‘èµ·æ”»å‡»: zero_update")

            elif self.attack_type == "scaled_update":
                # ç¼©æ”¾æ›´æ–°æ”»å‡»
                scale = self.config.get('byzantine_attack_scale', 10.0)
                weight_update = {k: scale * v for k, v in weight_update.items()}
                local_weights = {k: global_weights[k] + weight_update[k] for k in global_weights}
                print(f"  ğŸ˜ˆ [Round {current_round}] å®¢æˆ·ç«¯ {self.client_id} å‘èµ·æ”»å‡»: scaled_update (Ã—{scale})")

            else:
                # æœªçŸ¥æ”»å‡»ç±»å‹ï¼Œå›é€€åˆ°éšæœºæƒé‡
                for k in local_weights:
                    local_weights[k] = torch.randn_like(local_weights[k])
                weight_update = {k: local_weights[k] - global_weights[k] for k in global_weights}
                print(f"  âš ï¸ [Round {current_round}] å®¢æˆ·ç«¯ {self.client_id} ä½¿ç”¨æœªçŸ¥æ”»å‡» '{self.attack_type}' â†’ å›é€€åˆ° random_weights")

        self.local_weights = local_weights
        self.weight_update = weight_update

        return local_weights, 0.0

    def prepare_upload_data_simple(self, round_num):
        return {
            'local_weights': self.local_weights,
            'weight_update': self.weight_update
        }